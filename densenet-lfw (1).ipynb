{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport seaborn as sns\nimport kagglehub\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:03.949047Z","iopub.execute_input":"2024-12-17T03:32:03.949371Z","iopub.status.idle":"2024-12-17T03:32:16.534117Z","shell.execute_reply.started":"2024-12-17T03:32:03.949342Z","shell.execute_reply":"2024-12-17T03:32:16.533226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download the latest dataset version\npath = kagglehub.dataset_download(\"jessicali9530/lfw-dataset\")\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:19.438856Z","iopub.execute_input":"2024-12-17T03:32:19.439711Z","iopub.status.idle":"2024-12-17T03:32:19.957696Z","shell.execute_reply.started":"2024-12-17T03:32:19.439677Z","shell.execute_reply":"2024-12-17T03:32:19.956904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the folder containing images\nimage_folder = os.path.join(path, \"lfw-deepfunneled\")  # Update if folder name differs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:24.726907Z","iopub.execute_input":"2024-12-17T03:32:24.727533Z","iopub.status.idle":"2024-12-17T03:32:24.731395Z","shell.execute_reply.started":"2024-12-17T03:32:24.727502Z","shell.execute_reply":"2024-12-17T03:32:24.730404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List all images in the dataset folder\nimage_files = []\nfor root, dirs, files in os.walk(image_folder):\n    for file in files:\n        if file.endswith(('.jpg', '.jpeg', '.png')):  # Check for image files\n            image_files.append(os.path.join(root, file))\n\nprint(f\"Found {len(image_files)} image files.\")\n\n# Display the first ten images\nfor i, img_path in enumerate(image_files[:10]):\n    img = cv2.imread(img_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.figure(figsize=(2, 2))\n    plt.imshow(img_rgb)\n    plt.title(f\"Image {i+1}\")\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:28.865590Z","iopub.execute_input":"2024-12-17T03:32:28.865966Z","iopub.status.idle":"2024-12-17T03:32:50.068366Z","shell.execute_reply.started":"2024-12-17T03:32:28.865936Z","shell.execute_reply":"2024-12-17T03:32:50.067208Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing with Data Augmentation\ndef preprocess_images(image_paths, target_size=(224, 224)):\n    datagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\n    images = []\n    labels = []\n    for img_path in image_paths:\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, target_size)\n        img = img / 255.0\n        images.append(img)\n        label = img_path.split('/')[-2]\n        labels.append(label)\n\n    return np.array(images), np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:53.316737Z","iopub.execute_input":"2024-12-17T03:32:53.317535Z","iopub.status.idle":"2024-12-17T03:32:53.322936Z","shell.execute_reply.started":"2024-12-17T03:32:53.317502Z","shell.execute_reply":"2024-12-17T03:32:53.321955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess Images\nimages, labels = preprocess_images(image_files[:6000])\nprint(\"Processed images shape:\", images.shape)\nprint(\"Unique labels:\", set(labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:32:58.829939Z","iopub.execute_input":"2024-12-17T03:32:58.830621Z","iopub.status.idle":"2024-12-17T03:33:26.001259Z","shell.execute_reply.started":"2024-12-17T03:32:58.830589Z","shell.execute_reply":"2024-12-17T03:33:26.000326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label Encoding\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\ncategorical_labels = to_categorical(encoded_labels)\nprint(\"Encoded labels shape:\", categorical_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:36.289388Z","iopub.execute_input":"2024-12-17T03:33:36.290189Z","iopub.status.idle":"2024-12-17T03:33:36.309650Z","shell.execute_reply.started":"2024-12-17T03:33:36.290154Z","shell.execute_reply":"2024-12-17T03:33:36.308720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting Dataset\nX_train, X_val, y_train, y_val = train_test_split(images, categorical_labels, test_size=0.2, random_state=42)\nprint(\"Training set size:\", X_train.shape)\nprint(\"Validation set size:\", X_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:40.012753Z","iopub.execute_input":"2024-12-17T03:33:40.013150Z","iopub.status.idle":"2024-12-17T03:33:41.647208Z","shell.execute_reply.started":"2024-12-17T03:33:40.013119Z","shell.execute_reply":"2024-12-17T03:33:41.646350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Fine-Tuning\ndef create_densenet_model(input_shape=(224, 224, 3), num_classes=len(set(labels))):\n    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n    for layer in base_model.layers[-40:]:\n        layer.trainable = True\n\n    x = Flatten()(base_model.output)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)  # Adding dropout to prevent overfitting\n    output = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=base_model.input, outputs=output)\n    return model\n\nmodel = create_densenet_model()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:45.143780Z","iopub.execute_input":"2024-12-17T03:33:45.144589Z","iopub.status.idle":"2024-12-17T03:33:49.014907Z","shell.execute_reply.started":"2024-12-17T03:33:45.144554Z","shell.execute_reply":"2024-12-17T03:33:49.014126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the Model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),  # Lower initial learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:54.422730Z","iopub.execute_input":"2024-12-17T03:33:54.423487Z","iopub.status.idle":"2024-12-17T03:33:54.438729Z","shell.execute_reply.started":"2024-12-17T03:33:54.423455Z","shell.execute_reply":"2024-12-17T03:33:54.437966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training with Callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=40,  # Increase epochs with early stopping\n    batch_size=16,  # Adjust as per memory availability\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:58.321580Z","iopub.execute_input":"2024-12-17T03:33:58.322431Z","iopub.status.idle":"2024-12-17T03:58:32.909793Z","shell.execute_reply.started":"2024-12-17T03:33:58.322397Z","shell.execute_reply":"2024-12-17T03:58:32.909032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation Metrics Section\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\nplot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:59:47.626134Z","iopub.execute_input":"2024-12-17T03:59:47.632224Z","iopub.status.idle":"2024-12-17T03:59:48.149896Z","shell.execute_reply.started":"2024-12-17T03:59:47.632187Z","shell.execute_reply":"2024-12-17T03:59:48.149080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_binary_confusion_matrix(y_true, y_pred):\n    \"\"\"\n    Plots a binary confusion matrix indicating correct vs incorrect predictions.\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=['Incorrect', 'Correct'], \n                yticklabels=['Incorrect', 'Correct'])\n    \n    plt.xticks(rotation=0, fontsize=10)\n    plt.yticks(rotation=0, fontsize=10)\n    plt.xlabel('Predicted', fontsize=12)\n    plt.ylabel('True', fontsize=12)\n    plt.title('Binary Confusion Matrix', fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\n# Generate predictions\ny_pred = model.predict(X_val)  # Your original prediction step\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_val, axis=1)\n\n# Identify the indices of all correct predictions\ncorrect_indices = np.where(y_pred_classes == y_true)[0]\n\n# Print the first 50 correct predictions\nprint(\"First 50 Correct Predictions:\")\nfor idx in correct_indices[:50]:  # Limit to the first 50 correct predictions\n    print(f\"Index: {idx}, True Label: {y_true[idx]}, Predicted Label: {y_pred_classes[idx]}\")\n\n# Convert to binary classification (correct/incorrect)\ny_binary_true = (y_pred_classes == y_true)  # True for correct predictions, False otherwise\ny_binary_pred = y_binary_true  # Same as y_binary_true for binary confusion matrix\n\n# Plot the binary confusion matrix\nplot_binary_confusion_matrix(y_binary_true, y_binary_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:15:44.043340Z","iopub.execute_input":"2024-12-17T04:15:44.043714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def classification_metrics(y_true, y_pred, label_encoder):\n    # Find unique classes in y_true and y_pred\n    unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n    \n    # Map unique classes to their names using label_encoder\n    target_names = label_encoder.classes_[unique_classes]\n    \n    # Generate the classification report\n    report = classification_report(y_true, y_pred, labels=unique_classes, target_names=target_names)\n    print(\"Classification Report:\\n\", report)\n\n# Call the function\nclassification_metrics(y_true, y_pred_classes, label_encoder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:14:35.115259Z","iopub.execute_input":"2024-12-17T04:14:35.115635Z","iopub.status.idle":"2024-12-17T04:14:35.139049Z","shell.execute_reply.started":"2024-12-17T04:14:35.115605Z","shell.execute_reply":"2024-12-17T04:14:35.138181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC and AUC Section\ndef plot_roc_auc(y_true, y_pred):\n    fpr, tpr, _ = roc_curve(y_true.ravel(), y_pred.ravel())\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\n\nplot_roc_auc(y_val, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:12:13.154720Z","iopub.execute_input":"2024-12-17T04:12:13.155092Z","iopub.status.idle":"2024-12-17T04:12:13.933127Z","shell.execute_reply.started":"2024-12-17T04:12:13.155061Z","shell.execute_reply":"2024-12-17T04:12:13.932224Z"}},"outputs":[],"execution_count":null}]}